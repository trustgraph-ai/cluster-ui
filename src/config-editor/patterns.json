[
   {
      "module": "components/trustgraph.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "processing"
         ],
         "description": "This pattern adds DocumentRAG components for extracting and querying documents based on document embeddings.  You should make sure a vector store is included in your plan.",
         "features": [
            "document-rag"
         ],
         "icon": "ü§ùüòÇ",
         "name": "document-rag",
         "requires": [
            "pulsar",
            "trustgraph",
            "llm"
         ],
         "title": "Add DocumentRAG processing flow"
      }
   },
   {
      "module": "components/embeddings-hf.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "all-MiniLM-L6-v2",
               "description": "Embeddings model for sentence analysis",
               "label": "Embeddings model",
               "name": "embeddings-model",
               "options": [
                  {
                     "description": "all-MiniLM-L6-v2",
                     "id": "all-MiniLM-L6-v2"
                  },
                  {
                     "description": "mxbai-embed-large-v1",
                     "id": "mixedbread-ai/mxbai-embed-large-v1"
                  }
               ],
               "required": true,
               "type": "select"
            }
         ],
         "category": [
            "embeddings"
         ],
         "description": "This pattern integrates an embeddings model based on HuggingFace sentence-transformer library.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "embeddings-hf",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add embeddings model which uses HuggingFace models"
      }
   },
   {
      "module": "components/embeddings-hf.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "mxbai-embed-large",
               "description": "Embeddings model for sentence analysis",
               "label": "Embeddings model",
               "name": "embeddings-model",
               "options": [
                  {
                     "description": "mxbai-embed-large",
                     "id": "mxbai-embed-large"
                  }
               ],
               "required": true,
               "type": "select"
            },
            {
               "default": "http://ollama:11434",
               "description": "URL of the Ollama service",
               "label": "URL",
               "name": "ollama-url",
               "required": true,
               "type": "text",
               "width": 120
            }
         ],
         "category": [
            "embeddings"
         ],
         "description": "This pattern integrates an embeddings model based on HuggingFace sentence-transformer library.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "embeddings-ollama",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add embeddings model hosted on Ollama"
      }
   },
   {
      "module": "components/grafana.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "monitoring"
         ],
         "description": "System monitoring and dashboarding using Grafana and Prometheus",
         "features": [
            "prometheus",
            "grafana"
         ],
         "icon": "üìàüßØ",
         "name": "grafana",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add Prometheus and Grafana for monitoring and dashboards"
      }
   },
   {
      "module": "components/cassandra.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "knowledge-graph"
         ],
         "description": "GraphRAG processing needs a triple store.  This pattern adds a Cassandra store, along with plumbing so that Cassandra is integrated with GraphRag indexing and querying.",
         "features": [
            "cassandra",
            "triple-store"
         ],
         "icon": "üñáÔ∏èüôã‚Äç‚ôÄÔ∏è",
         "name": "triple-store-cassandra",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Adds a Cassandra store configured to act as a triple store"
      }
   },
   {
      "module": "components/neo4j.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "knowledge-graph"
         ],
         "description": "GraphRAG processing needs a triple store.  This pattern adds a Cassandra store, along with plumbing so that Cassandra is integrated with GraphRag indexing and querying.",
         "features": [
            "neo4j",
            "triple-store"
         ],
         "icon": "üñáÔ∏èüôã‚Äç‚ôÄÔ∏è",
         "name": "triple-store-neo4j",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Adds a Neo4j store configured to act as a triple store."
      }
   },
   {
      "module": "components/trustgraph.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 50,
               "description": "Limit on entities to fetch from vector store",
               "label": "GraphRAG entity query limit",
               "name": "graph-rag-entity-limit",
               "required": true,
               "type": "integer"
            },
            {
               "default": 30,
               "description": "Limit on triples to fetch from triple store",
               "label": "GraphRAG triple query limit",
               "name": "graph-rag-triple-limit",
               "required": true,
               "type": "integer"
            },
            {
               "default": 3000,
               "description": "Limit on size of subgraph to present to text-completion model",
               "label": "GraphRAG maximum subgraph size",
               "name": "graph-rag-max-subgraph-size",
               "required": true,
               "type": "integer"
            }
         ],
         "category": [
            "processing"
         ],
         "description": "This pattern adds GraphRAG components for extracting and querying graph edges.  You should make sure a triple store and vector store are included in your plan.",
         "features": [
            "graph-rag"
         ],
         "icon": "ü§ùüòÇ",
         "name": "graph-rag",
         "requires": [
            "pulsar",
            "trustgraph",
            "llm"
         ],
         "title": "Add GraphRAG processing flow"
      }
   },
   {
      "module": "components/azure.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 4096,
               "description": "Limit on number tokens to generate",
               "label": "Maximum output tokens",
               "name": "azure-max-output-tokens",
               "required": true,
               "type": "integer"
            },
            {
               "default": 0.5,
               "description": "Controlling predictability / creativity balance",
               "label": "Temperature",
               "max": 1,
               "min": 0,
               "name": "azure-temperature",
               "step": 0.050000000000000003,
               "type": "slider"
            }
         ],
         "category": [
            "llm"
         ],
         "description": "This pattern integrates an Azure LLM endpoint hosted in the Azure cloud for text completion operations.  You need an Azure subscription and to have an endpoint deployed to be able to use this service.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "azure",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add Azure LLM endpoint for text completion"
      }
   },
   {
      "module": "components/bedrock.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 4096,
               "description": "Limit on number tokens to generate",
               "label": "Maximum output tokens",
               "name": "bedrock-max-output-tokens",
               "required": true,
               "type": "integer"
            },
            {
               "default": 0.5,
               "description": "Controlling predictability / creativity balance",
               "label": "Temperature",
               "max": 1,
               "min": 0,
               "name": "bedrock-temperature",
               "step": 0.050000000000000003,
               "type": "slider"
            }
         ],
         "category": [
            "llm"
         ],
         "description": "This pattern integrates an AWS Bedrock LLM service hosted in the AWS cloud for text completion operations.  You need an AWS cloud subscription and to have Bedrock configured to be able to use this service.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "bedrock",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add AWS Bedrock for text completion"
      }
   },
   {
      "module": "components/claude.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 4096,
               "description": "Limit on number tokens to generate",
               "label": "Maximum output tokens",
               "name": "claude-max-output-tokens",
               "required": true,
               "type": "integer"
            },
            {
               "default": 0.5,
               "description": "Controlling predictability / creativity balance",
               "label": "Temperature",
               "max": 1,
               "min": 0,
               "name": "claude-temperature",
               "step": 0.050000000000000003,
               "type": "slider"
            }
         ],
         "category": [
            "llm"
         ],
         "description": "This pattern integrates an Anthropic Claude LLM service for text completion operations.  You need a Claude subscription to be able to use this service.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "claude",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add Anthropic Claude for text completion"
      }
   },
   {
      "module": "components/cohere.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 4096,
               "description": "Limit on number tokens to generate",
               "label": "Maximum output tokens",
               "name": "cohere-max-output-tokens",
               "required": true,
               "type": "integer"
            },
            {
               "default": 0.5,
               "description": "Controlling predictability / creativity balance",
               "label": "Temperature",
               "max": 1,
               "min": 0,
               "name": "cohere-temperature",
               "step": 0.050000000000000003,
               "type": "slider"
            }
         ],
         "category": [
            "llm"
         ],
         "description": "This pattern integrates the Cohere LLM service for text completion operations.  You need a Cohere subscription and API keys to be able to use this service.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "cohere",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add Cohere LLM endpoint for text completion"
      }
   },
   {
      "module": "components/ollama.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 4096,
               "description": "Limit on number tokens to generate",
               "label": "Maximum output tokens",
               "name": "ollama-max-output-tokens",
               "required": true,
               "type": "integer"
            },
            {
               "default": 0.5,
               "description": "Controlling predictability / creativity balance",
               "label": "Temperature",
               "max": 1,
               "min": 0,
               "name": "ollama-temperature",
               "step": 0.050000000000000003,
               "type": "slider"
            },
            {
               "default": "http://ollama:11434",
               "description": "URL of the Ollama service",
               "label": "URL",
               "name": "ollama-url",
               "required": true,
               "type": "text",
               "width": 120
            }
         ],
         "category": [
            "llm"
         ],
         "description": "This pattern integrates an Ollama service for text completion operations.  You need to have a running Ollama service with the necessary models added in order to be able to use this service.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "ollama",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add Ollama LLM for text completion"
      }
   },
   {
      "module": "components/openai.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 4096,
               "description": "Limit on number tokens to generate",
               "label": "Maximum output tokens",
               "name": "openai-max-output-tokens",
               "required": true,
               "type": "integer"
            },
            {
               "default": 0.5,
               "description": "Controlling predictability / creativity balance",
               "label": "Temperature",
               "max": 1,
               "min": 0,
               "name": "openai-temperature",
               "step": 0.050000000000000003,
               "type": "slider"
            }
         ],
         "category": [
            "llm"
         ],
         "description": "This pattern integrates an OpenAI LLM service for text completion operations.  You need an OpenAI subscription and have an API key to be able to use this service.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "openai",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add OpenAI LLM endpoint for text completion"
      }
   },
   {
      "module": "components/vertexai.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 4096,
               "description": "Limit on number tokens to generate",
               "label": "Maximum output tokens",
               "name": "vertexai-max-output-tokens",
               "required": true,
               "type": "integer"
            },
            {
               "default": 0.5,
               "description": "Controlling predictability / creativity balance",
               "label": "Temperature",
               "max": 1,
               "min": 0,
               "name": "vertexai-temperature",
               "step": 0.050000000000000003,
               "type": "slider"
            }
         ],
         "category": [
            "llm"
         ],
         "description": "This pattern integrates a VertexAI endpoint hosted in Google Cloud for text completion operations.  You need a GCP subscription and to have VertexAI enabled to be able to use this service.",
         "features": [
            "llm"
         ],
         "icon": "ü§ñüí¨",
         "name": "vertexai",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add Google Cloud VertexAI LLM for text completion"
      }
   },
   {
      "module": "components/cassandra.jsonnet",
      "pattern": {
         "args": [
            {
               "default": 2000,
               "description": "Chunk size value",
               "name": "chunk-size",
               "required": true,
               "type": "integer"
            },
            {
               "default": 100,
               "description": "Overlap size value",
               "name": "chunk-overlap",
               "required": true,
               "type": "integer"
            }
         ],
         "category": [
            "chunking"
         ],
         "description": "The default chunker used in Trustgraph core is a token-based chunker.  This pattern replaces that with a recursive chunker, and allows ou to configure the chunking parameters.",
         "features": [ ],
         "icon": "‚úÇÔ∏èü™ö",
         "name": "override-recursive-chunker",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Replace default chunker with recursive chunker"
      }
   },
   {
      "module": "components/null.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "<instructions>\nStudy the following text and derive definitions for any discovered entities.\nDo not provide definitions for entities whose definitions are incomplete\nor unknown.\nOutput relationships in JSON format as an arary of objects with fields:\n- entity: the name of the entity\n- definition: English text which defines the entity\n</instructions>\n\n<text>\n{text}\n</text>\n\n<requirements>\nYou will respond only with raw JSON format data. Do not provide\nexplanations. Do not use special characters in the abstract text. The\nabstract will be written as plain text.  Do not add markdown formatting\nor headers or prefixes.  Do not include null or unknown definitions.\n</requirements>",
               "description": "Definition extraction prompt",
               "name": "prompt-definition-template",
               "required": true,
               "rows": 10,
               "size": 2000,
               "type": "multiline"
            }
         ],
         "category": [
            "prompting"
         ],
         "description": "This pattern overrides the default definition extraction LLM prompt allowing you to provide your own prompt.",
         "features": [
            "extract-definition-prompt"
         ],
         "icon": "üìúÔ∏èÔ∏èüí¨",
         "name": "prompt-template-definitions",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Override definition extraction prompt"
      }
   },
   {
      "module": "components/null.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "Study the following context. Use only the information provided in the context in your response. Do not speculate if the answer is not found in the provided set of knowledge statements.\n\nHere is the context:\n{documents}\n\nUse only the provided knowledge statements to respond to the following:\n{query}\n",
               "description": "Document query prompt",
               "name": "prompt-document-query-template",
               "required": true,
               "rows": 10,
               "size": 2000,
               "type": "multiline"
            }
         ],
         "category": [
            "prompting"
         ],
         "description": "This pattern overrides the default document query prompt used for DocumentRAG allowing you to specify your own prompt.",
         "features": [
            "document-query-prompt"
         ],
         "icon": "üìúÔ∏èÔ∏èüí¨",
         "name": "prompt-template-document-query",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Override document query prompt"
      }
   },
   {
      "module": "components/null.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "Study the following set of knowledge statements. The statements are written in Cypher format that has been extracted from a knowledge graph. Use only the provided set of knowledge statements in your response. Do not speculate if the answer is not found in the provided set of knowledge statements.\n\nHere's the knowledge statements:\n{graph}\n\nUse only the provided knowledge statements to respond to the following:\n{query}\n",
               "description": "Knowledge graph extraction prompt",
               "name": "prompt-knowledge-query-template",
               "required": true,
               "rows": 10,
               "size": 2000,
               "type": "multiline"
            }
         ],
         "category": [
            "prompting"
         ],
         "description": "This pattern overrides the default knowledge query LLM prompt allowing you to provide your own prompt.",
         "features": [
            "kg-query-prompt"
         ],
         "icon": "üìúÔ∏èÔ∏èüí¨",
         "name": "prompt-template-kq-query",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Override knowledge query prompt"
      }
   },
   {
      "module": "components/null.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "<instructions>\nStudy the following text and derive entity relationships.  For each\nrelationship, derive the subject, predicate and object of the relationship.\nOutput relationships in JSON format as an arary of objects with fields:\n- subject: the subject of the relationship\n- predicate: the predicate\n- object: the object of the relationship\n- object-entity: false if the object is a simple data type: name, value or date.  true if it is an entity.\n</instructions>\n\n<text>\n{text}\n</text>\n\n<requirements>\nYou will respond only with raw JSON format data. Do not provide\nexplanations. Do not use special characters in the abstract text. The\nabstract must be written as plain text.  Do not add markdown formatting\nor headers or prefixes.\n</requirements>",
               "description": "Relationship extraction prompt",
               "name": "prompt-relationship-template",
               "required": true,
               "rows": 10,
               "size": 2000,
               "type": "multiline"
            }
         ],
         "category": [
            "prompting"
         ],
         "description": "This pattern overrides the default relationship extraction LLM prompt allowing you to provide your own prompt.",
         "features": [
            "extract-relationship-prompt"
         ],
         "icon": "üìúÔ∏èÔ∏èüí¨",
         "name": "prompt-template-relationships",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Override relationship extraction prompt"
      }
   },
   {
      "module": "components/null.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "<instructions>\nStudy the following text and derive objects which match the schema provided.\n\nYou must output an array of JSON objects for each object you discover\nwhich matches the schema.  For each object, output a JSON object whose fields\ncarry the name field specified in the schema.\n</instructions>\n\n<schema>\n{schema}\n</schema>\n\n<text>\n{text}\n</text>\n\n<requirements>\nYou will respond only with raw JSON format data. Do not provide\nexplanations. Do not add markdown formatting or headers or prefixes.\n</requirements>",
               "description": "Row data extraction prompt",
               "name": "prompt-rows-template",
               "required": true,
               "rows": 10,
               "size": 2000,
               "type": "multiline"
            }
         ],
         "category": [
            "prompting"
         ],
         "description": "This pattern overrides the default table/row extraction prompt to be changed.  This is used for DatabaseRAG pipelines.",
         "features": [
            "extract-rows-prompt"
         ],
         "icon": "üìúÔ∏èÔ∏èüí¨",
         "name": "prompt-template-rows-template",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Override table/row extraction prompt"
      }
   },
   {
      "module": "components/pulsar.jsonnet",
      "pattern": {
         "args": [
            {
               "default": "pulsaradmin",
               "description": "Admin password to apply at initialisation",
               "label": "Password",
               "name": "initial-admin-password",
               "required": true,
               "type": "text",
               "width": 40
            }
         ],
         "category": [
            "foundation"
         ],
         "description": "Adds Pulsar Manager which provides a web interface to manage Pulsar.  Pulsar Manager is a large container and deployment requiring over 1GB of RAM, so is not deployed by default.  This is not a required component, it may be useful to help manage a large operational deployment.",
         "features": [
            "pulsar-manager"
         ],
         "icon": "üèªüõÉ",
         "name": "pulsar-manager",
         "requires": [
            "pulsar"
         ],
         "title": "Add Pulsar Manager"
      }
   },
   {
      "module": "components/pulsar.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "foundation"
         ],
         "description": "Deploy Pulsar as the inter-process messaging fabric.  Pulsar is a Cloud-native, distributed messaging and Streaming. Apache Pulsar is an open-source, distributed messaging and streaming platform built for the cloud.  Trustgraph uses Pulsar to manage the message flow between all components.",
         "features": [
            "pulsar"
         ],
         "icon": "üåü‚òÑÔ∏è",
         "name": "pulsar",
         "requires": [ ],
         "title": "Deploy foundation messaging fabric"
      }
   },
   {
      "module": "components/trustgraph.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "foundation"
         ],
         "description": "This pattern adds a core set of Trustgraph flows, including PDF ingest, chunking, embeddings, and knowledge graph extraction.  You should also consider adding an LLM and at least one RAG processing flow.",
         "features": [
            "trustgraph"
         ],
         "icon": "ü§ùüòÇ",
         "name": "trustgraph-base",
         "requires": [
            "pulsar"
         ],
         "title": "Add Trustgraph base processing flows"
      }
   },
   {
      "module": "components/milvus.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "vector-store"
         ],
         "description": "The Trustgraph core does not include a vector store by default.  This configuration pattern adds a simple Milvus store and integrates with embeddings handling.",
         "features": [
            "milvus",
            "vectordb"
         ],
         "icon": "‚ùìüåê",
         "name": "vector-store-milvus",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Add Milvus, a vector embeddings store"
      }
   },
   {
      "module": "components/qdrant.jsonnet",
      "pattern": {
         "args": [ ],
         "category": [
            "vector-store"
         ],
         "description": "The Trustgraph core does not include a vector store by default.  This configuration pattern adds a simple Qdrant store and integrates with embeddings handling.",
         "features": [
            "qdrant",
            "vectordb"
         ],
         "icon": "‚ùìüåê",
         "name": "vector-store-qdrant",
         "requires": [
            "pulsar",
            "trustgraph"
         ],
         "title": "Adds Qdrant, a vector embeddings store"
      }
   }
]
